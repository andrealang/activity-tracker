---

copyright:
  years: 2019
lastupdated: "2019-07-18"

keywords: IBM Cloud, LogDNA, Activity Tracker, manage events

subcollection: logdnaat

---

{:new_window: target="_blank"}
{:shortdesc: .shortdesc}
{:screen: .screen}
{:pre: .pre}
{:table: .aria-labeledby="caption"}
{:codeblock: .codeblock}
{:tip: .tip}
{:download: .download}
{:important: .important}
{:note: .note}


# Managing events in your account
{: #manage_events}

As an administrator of the {{site.data.keyword.at_full_notm}} service in the {{site.data.keyword.cloud_notm}}, you provision an instance of the service in each location that you plan to monitor. You also define the account guidelines to manage events in the account such as maanging keys, configuring archiving, and classifying views and dashboards into categories.
{:shortdesc}


## Provisioning an instance of the service per location
{: #manage_events_provision}

To collect and monitor activity in your account, you must provision the {{site.data.keyword.at_full_notm}} service in your account. 

* There is 1 instance of the {{site.data.keyword.at_full_notm}} service per location.
* To monitor [global events](/docs/services/Activity-Tracker-with-LogDNA?topic=logdnaat-monitor_events#mon_def_global), you must provision 1 instance in Frankfurt. 
{: note}

Notice that to monitor activity in your account, you might need to provision multiple {{site.data.keyword.at_full_notm}} instances. For example, you have services in the US South location only. To monitor activity in your account, you need 1 instance in US South to monitor events that are generated by services that are running in that location. You need 1 instance in EU-DE (Frankfurt) to monitor global actions that happen in your account such as user management actions, and provisioning of service instances. 

In the {{site.data.keyword.cloud_notm}}, you can click the **Menu** icon ![Menu icon](../icons/icon_hamburger.svg) > **Observability** > **Activity Tracker** to see the dashboard where all the instances that are provisioned in the account are listed. 

[Learn more about provisioning the service](/docs/services/Activity-Tracker-with-LogDNA?topic=logdnaat-provision).

To get the list of locations where the service is available in the {{site.data.keyword.cloud_notm}}, see [Locations](/docs/services/Activity-Tracker-with-LogDNA?topic=logdnaat-regions).

As soon as an instance is available, events are collected and available for monitoring through the web UI of that instance.



## Archiving events
{: #manage_events_archive}

You can archive events from an {{site.data.keyword.at_full_notm}} instance into a bucket in an {{site.data.keyword.cos_full_notm}} (COS) instance. [Learn more](/docs/services/Activity-Tracker-with-LogDNA?topic=logdnaat-archiving).

* Events are automatically archived once a day in a compressed format **(.json.gz)**. Each event preserves its metadata.
* Events are archived within 24-48 hours after you save the configuration. 
* The events that are archived on a file correspond to a single day of data. **The timestamp that is used to determine whether the event is included in an archive is the UTC timestamp.**

    Notice that depending on your location, there might be events that you see in local time in your views on a specific day. However, you cannot find them on the archive file for that day. You are most likely viewing events in local time and the archive process uses the UTC timestamp of the event.

* After you configure archiving, the first archive file is created when the archiving process runs and there is data.
* The first time the archive process runs, you get an archive file for each day that you have data.

    * The maximum number of days that is archived includes events for the past 30 days when the instance has a `30 day search` plan.

    * The maximum number of days that is archived includes events for the past 14 days when the instance has a `14 day search` plan.

    * The maximum number of days that is archived includes events for the past 7 days when the instance has a `7 day search` plan.

For example, you have a service plan of 30 days. You configured the instance 10 days ago. You enable archiving on the 10th day. Your first archive generates 10 files, one for each day that you have data, Each file includes events for that date. If there is no data on a specific day, the archive file is empty.

Each {{site.data.keyword.at_full_notm}} instance has its own archiving configuration.
{: important}

The following figure shows a high-level view of the different components that are integrated when archiving events:

![High-level view archiving events](images/archive.png "High-level view archiving events")

The {{site.data.keyword.cos_full_notm}} instance is provisioned within the context of a resource group. The {{site.data.keyword.at_full_notm}} instance is also provisioned within the context of a resource group. Both instances can be grouped under the same resource group or in different ones. 

{{site.data.keyword.at_full_notm}} uses a service ID to communicate with the {{site.data.keyword.cos_full_notm}} service.
* The service ID that you create for an {{site.data.keyword.cos_full_notm}} instance is used by the {{site.data.keyword.at_full_notm}} to authenticate and access the {{site.data.keyword.cos_full_notm}} instance. 
* You can assign specific access policies to the service ID that restrict permissions on the {{site.data.keyword.cos_full_notm}} instance. Restrict the service ID to only have writing permissions on the bucket where you plan to archive the events.

**Archiving in an EU-managed location:** You must configure a bucket that complies with the EU-managed and GDPR regulations.
{: important}



## Classifying events by using categories
{: #manage_events_category}

You can define categories through the **Categories** section in the web UI. 

* You can define categories to group views. 
* You can define a different set of categories to group dashboards.

Use categories to group resources so users can easily find them. 
{: tip}






