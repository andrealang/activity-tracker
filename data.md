---

copyright:
  years: 2019
lastupdated: "2019-10-14"

keywords: IBM Cloud, LogDNA, Activity Tracker, data

subcollection: logdnaat

---

{:new_window: target="_blank"}
{:shortdesc: .shortdesc}
{:screen: .screen}
{:pre: .pre}
{:table: .aria-labeledby="caption"}
{:codeblock: .codeblock}
{:tip: .tip}
{:download: .download}
{:important: .important}
{:note: .note}

# Data
{: #data}

Learn how data is collected, managed, and deleted within the {{site.data.keyword.at_full}}.
{:shortdesc}


## Data collection
{: #data_collection}

Data from [{{site.data.keyword.cloud_notm}} services and resources](/docs/services/Activity-Tracker-with-LogDNA?topic=logdnaat-cloud_services) is collected automatically and available for analysis through the web UI. 

{{site.data.keyword.at_full_notm}} collects management and data events from {{site.data.keyword.cloud_notm}} services and resources: 
* **Management Events** are generated when an API call changes the state of a Cloud resource. A resource might be an entire service instance or a resource managed by the service. 
* **Data Events** are generated when an API call reads or modifies a resource's data. 


## Data location
{: #data_location}

Data is hosted on the {{site.data.keyword.cloud_notm}}. The {{site.data.keyword.at_full_notm}} service is operated by LogDNA.

Data does not leave {{site.data.keyword.cloud_notm}}.

Events can be classified as global or location-based. [Learn more](/docs/services/Activity-Tracker-with-LogDNA?topic=logdnaat-monitor_events#mon_def_event_type).
* **Location-based events** report on activity in your account that is generated by {{site.data.keyword.cloud_notm}} services that are hosted within an {{site.data.keyword.IBM_notm}} data center location, like Dallas or Frankfurt. Location-based events maintain data locality to the services that run in that Cloud location.
* **Global events** report on activity in your account that relate to data and resources that are generally synchronized across all regions. The global domain is set in **Frankfurt**. Global events are captured and made available through the {{site.data.keyword.at_full_notm}} instance that is configured in Frankfurt.


## Data encryption
{: #data_encryption}

All the data that is hosted in a LogDNA instance is encrypted at rest using **AES 256**.

When an {{site.data.keyword.cloud_notm}} service sends data to a LogDNA instance, data is encrypted in transit over HTTPS.

When a user requests an export, the data is encrypted during transit, and is also encrypted at rest in {{site.data.keyword.cos_full_notm}} (COS).


## Data retention for search
{: #data_retention}

The service plan that you choose for an {{site.data.keyword.at_full_notm}} instance defines the number of days that data is stored and retained in LogDNA. 

For example, if you choose the *Lite* plan, data is not stored at all. However, if you choose the 7-day plan, data is stored for 7 days and you have access to it through the LogDNA Web UI.



## Data availability
{: #data_availability}

Data is collected and aggregated in each {{site.data.keyword.cloud_notm}} location where the service is available. 

Each supported location is a multi-zone region (MZR), except Seoul that is a single-zone region (SZR). [Learn more](/docs/services/Activity-Tracker-with-LogDNA?topic=logdnaat-regions).

## Data archives
{: #data_archives}

You can archive events from an {{site.data.keyword.at_full_notm}} instance into a bucket in an {{site.data.keyword.cos_full_notm}} (COS) instance. [Learn more](/docs/services/Activity-Tracker-with-LogDNA?topic=logdnaat-archiving).

When data is archived, data going from LogDNA to {{site.data.keyword.cos_full_notm}} (COS) is encrypted in transit over HTTPS.

You must configure archiving to a COS instance if you want to backup your events for long term storage.

You can use the {{site.data.keyword.sqlquery_short}} service to query data in archive files that are stored in an {{site.data.keyword.cos_short}} (COS) bucket in your account. You can run queries from the {{site.data.keyword.cloud_notm}} UI, or programmatically.

## Data exports
{: #data_exports}

You can export data in JSONL format locally, write data to your terminal, or request an email with a link to the data. [Learn more](/docs/services/Activity-Tracker-with-LogDNA?topic=logdnaat-export).

Consider the following information when you export log data:
* You export a set of event entries. To define the set of data that you want to export, you can apply filter and searches. You can also specify the time range. 
* From the Web UI, when you export events, you get an email that is sent to your email address, with a link to a compressed file that includes the data. To get the data, you must click the link and download the compressed file. Notice that the link expires automatically after 12 hours.
* When you export events programmatically, you can choose to send an email, or to write to the terminal.
* The compressed file that contains the data that you want to export is available for a maximum of 12 hours. 
* When you export data, you have a limit of lines that you can export in a request. You can specify to export older lines or newer lines in case you reach the limit in the time range that you specify for the export.

Exported data is hosted in {{site.data.keyword.cos_full_notm}} (COS).

At all times, the data remains in {{site.data.keyword.cloud_notm}}.

## Data deletion
{: #data_deletion}

When you delete a LogDNA instance, the instance is automatically deactivated, and ingestion of events is stopped. [Learn more](/docs/services/Activity-Tracker-with-LogDNA?topic=logdnaat-remove).

LogDNA deletes all events that are already ingested. Deletion is completed within 24 hours after receiving your request.

You are responsible for managing archived data. 


